{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM, SVR\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###LOAD DATASET \n",
    "df = pd.read_csv('../merged_dataset/merged_logs20000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec for feature extraction\n",
    "def tokenize_message(message):\n",
    "    return message.lower().split()\n",
    "\n",
    "# Train Word2Vec model\n",
    "tokenized_messages = df['message'].apply(tokenize_message)\n",
    "word2vec_model = Word2Vec(sentences=tokenized_messages, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# Create Word2Vec embeddings for each message\n",
    "df['word2vec_vector'] = df['message'].apply(lambda msg: np.mean([word2vec_model.wv[token] for token in tokenize_message(msg) if token in word2vec_model.wv], axis=0))\n",
    "word2vec_features = np.vstack(df['word2vec_vector'].values)\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=10)\n",
    "word2vec_reduced = pca.fit_transform(word2vec_features)\n",
    "\n",
    "# Reshape message_length to match dimensions\n",
    "message_length_reshaped = df['message_length'].values.reshape(-1, 1)\n",
    "\n",
    "# Combine Word2Vec features with other features\n",
    "X = np.hstack([word2vec_reduced, message_length_reshaped])\n",
    "\n",
    "#Target variable\n",
    "y = df['combined_anomaly']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising and Handling Imbalance\n",
    "\n",
    "#Standadize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01452621395822239\n",
      "Root Mean Squared Error (RMSE): 0.12052474417405909\n",
      "Mean Absolute Error (MAE): 0.10524192098242793\n",
      "R^2 Score: 0.7603509296376346\n",
      "Explained Variance Score: 0.7903426630852783\n"
     ]
    }
   ],
   "source": [
    "#SVM!!!!\n",
    "#Split dataset for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, df['combined_anomaly'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#Init SVR\n",
    "svr = SVR(kernel='linear', gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Converting prediction\n",
    "#y_pred = [1 if i == -1 else 0 for i in y_pred]\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "\n",
    "#Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "explained_variance = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "print(f'Explained Variance Score: {explained_variance}')\n",
    "\n",
    "\n",
    "# Log misclassified instances\n",
    "\n",
    "misclassified_indices = np.where(np.abs(y_pred - y_test) > 0.5)[0]\n",
    "misclassified_samples = df.iloc[misclassified_indices]\n",
    "\n",
    "# Save misclassified samples to a CSV file for further analysis\n",
    "misclassified_samples.to_csv('../log/misclassified_samples.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72229e2cb4a4d3f9a66c0f3bbf8721a4f899e8fc91e357b565a53efd017c27d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
